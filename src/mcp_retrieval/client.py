#!/usr/bin/env python3
"""
LangGraph Client for Astrophysics TAP Query System

è¿™æ˜¯ä¸€ä¸ªLangGraphå®¢æˆ·ç«¯ï¼Œä½¿ç”¨è±†åŒ…APIä½œä¸ºLLMï¼Œé€šè¿‡MCPé€‚é…å™¨ä¸å¤©ä½“ç‰©ç†å­¦TAPæŸ¥è¯¢æœåŠ¡å™¨é€šä¿¡ã€‚
æ”¯æŒè‡ªç„¶è¯­è¨€è¾“å…¥ï¼Œè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·æ‰§è¡ŒæŸ¥è¯¢ã€‚
"""

import asyncio
import logging
import os
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import BaseTool
try:
    from langchain_openai import ChatOpenAI
except ImportError:
    try:
        from langchain_community.chat_models import ChatOpenAI
    except ImportError:
        print("è­¦å‘Š: æ— æ³•å¯¼å…¥ChatOpenAIï¼Œè¯·æ£€æŸ¥langchainå®‰è£…")
        ChatOpenAI = None
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from typing_extensions import TypedDict, Annotated

try:
    from langchain_mcp_adapters.tools import MCPTool, load_mcp_tools
    from mcp.client.session import ClientSession
    from mcp.client.stdio import stdio_client, StdioServerParameters
except ImportError:
    print("è­¦å‘Š: langchain-mcp-adapters æˆ– mcp æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install langchain-mcp-adapters mcp")
    MCPTool = None
    load_mcp_tools = None
    ClientSession = None
    stdio_client = None
    StdioServerParameters = None

# å¯¼å…¥é¡¹ç›®é…ç½®ç³»ç»Ÿ
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from src.config.loader import load_yaml_config

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class State(TypedDict):
    """å›¾çŠ¶æ€å®šä¹‰"""
    messages: Annotated[List, add_messages]
    user_query: str
    selected_tools: List[str]
    query_results: Dict[str, Any]
    final_response: str

class AstrophysicsQueryClient:
    """
    å¤©ä½“ç‰©ç†å­¦æŸ¥è¯¢å®¢æˆ·ç«¯
    
    ä½¿ç”¨LangGraphæ„å»ºæŸ¥è¯¢æµç¨‹ï¼Œé›†æˆè±†åŒ…APIå’ŒMCPå·¥å…·
    """
    
    def __init__(self):
        logger.info("ğŸ—ï¸ åˆå§‹åŒ–å¤©ä½“ç‰©ç†å­¦æŸ¥è¯¢å®¢æˆ·ç«¯...")
        self.llm = None
        self.mcp_tools = []
        self.graph = None
        
        self._setup_llm()
        self._setup_mock_tools()
        self._build_graph()
        
        logger.info("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize_mcp(self):
        """å¼‚æ­¥åˆå§‹åŒ–MCPå·¥å…·"""
        await self._setup_mcp_tools()
        # é‡æ–°æ„å»ºå›¾ä»¥ä½¿ç”¨MCPå·¥å…·
        self._build_graph()
    
    def _setup_llm(self):
        """è®¾ç½®è±†åŒ…API LLM"""
        try:
            # ä»conf.yamlåŠ è½½é…ç½®
            config_path = os.path.join(os.path.dirname(__file__), '..', '..', 'conf.yaml')
            conf = load_yaml_config(config_path)
            basic_model_conf = conf.get('BASIC_MODEL', {})
            
            # è·å–è±†åŒ…APIé…ç½®
            api_key = basic_model_conf.get('api_key')
            base_url = basic_model_conf.get('base_url', 'https://ark.cn-beijing.volces.com/api/v3')
            model = basic_model_conf.get('model', 'doubao-pro-4k')
            
            if not api_key:
                raise ValueError("è¯·åœ¨conf.yamlæ–‡ä»¶ä¸­è®¾ç½®BASIC_MODEL.api_key")
            
            # ä½¿ç”¨OpenAIå…¼å®¹æ¥å£è¿æ¥è±†åŒ…ï¼Œå¹¶ç»‘å®šå·¥å…·
            self.llm = ChatOpenAI(
                model=model,
                openai_api_key=api_key,
                openai_api_base=base_url,
                temperature=0.1,
                max_tokens=2000
            )
            logger.info(f"è±†åŒ…API LLM åˆå§‹åŒ–æˆåŠŸ - æ¨¡å‹: {model}, åŸºç¡€URL: {base_url}")
            
        except Exception as e:
            logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    async def _setup_mcp_tools(self):
        """è®¾ç½®MCPå·¥å…·é€‚é…å™¨"""
        if MCPTool is None or load_mcp_tools is None or ClientSession is None:
            logger.warning("MCPé€‚é…å™¨ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç›´æ¥è°ƒç”¨å·¥å…·")
            self._setup_mock_tools()
            return
        
        try:
            # åˆ›å»ºMCPä¼šè¯
            import shutil
            python_path = shutil.which('python')
            
            server_params = StdioServerParameters(
                command=python_path,
                args=['server.py']
            )
            
            # åˆ›å»ºå¼‚æ­¥ä¼šè¯å¹¶åŠ è½½å·¥å…·
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()
                    self.mcp_tools = await load_mcp_tools(session=session)
                    logger.info(f"æˆåŠŸè¿æ¥MCPæœåŠ¡å™¨ï¼Œè·å–åˆ° {len(self.mcp_tools)} ä¸ªå·¥å…·")
            
        except Exception as e:
            logger.error(f"MCPå·¥å…·è®¾ç½®å¤±è´¥: {str(e)}")
            logger.info("ä½¿ç”¨ç›´æ¥è°ƒç”¨å·¥å…·ä»£æ›¿")
            self._setup_mock_tools()
    
    def _setup_mock_tools(self):
        """è®¾ç½®çœŸå®å·¥å…·ï¼ˆå½“MCPä¸å¯ç”¨æ—¶ï¼Œç›´æ¥è°ƒç”¨å·¥å…·å‡½æ•°ï¼‰"""
        from langchain_core.tools import tool
        from .tools import get_object_by_identifier as _get_object_by_identifier
        from .tools import get_bibliographic_data as _get_bibliographic_data
        from .tools import search_objects_by_coordinates as _search_objects_by_coordinates
        
        @tool
        def get_object_by_identifier(object_id: str) -> str:
            """
            æ ¹æ®å¤©ä½“æ ‡è¯†ç¬¦è·å–åŸºç¡€å¤©æ–‡æ•°æ®
            
            è¿™ä¸ªå·¥å…·ç”¨äºæŸ¥è¯¢å¤©ä½“çš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
            - å¤©ä½“åæ ‡ï¼ˆèµ¤ç»ã€èµ¤çº¬ï¼‰
            - ä¸»è¦æ ‡è¯†ç¬¦
            - è§†å·®å’Œå¾„å‘é€Ÿåº¦
            - æ˜Ÿç³»å°ºå¯¸å’Œè§’åº¦
            - å‚è€ƒæ–‡çŒ®æ•°é‡
            
            å‚æ•°:
                object_id (str): å¤©ä½“æ ‡è¯†ç¬¦ï¼Œå¦‚ 'M13', 'NGC 6205', 'Vega', 'Sirius' ç­‰
            
            è¿”å›:
                str: åŒ…å«å¤©ä½“åŸºç¡€ä¿¡æ¯çš„JSONæ ¼å¼å­—ç¬¦ä¸²
            
            ä½¿ç”¨åœºæ™¯:
            - ç”¨æˆ·è¯¢é—®å¤©ä½“çš„åŸºæœ¬ä¿¡æ¯
            - éœ€è¦è·å–å¤©ä½“çš„åæ ‡å’Œç‰©ç†å‚æ•°
            - æŸ¥è¯¢ç‰¹å®šå¤©ä½“çš„åŸºæœ¬å±æ€§
            """
            try:
                result = _get_object_by_identifier(object_id)
                return str(result)
            except Exception as e:
                return f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
        
        @tool
        def get_bibliographic_data(object_id: str) -> str:
            """
            æ ¹æ®å¤©ä½“æ ‡è¯†ç¬¦è·å–ç›¸å…³çš„å‚è€ƒæ–‡çŒ®å’Œå­¦æœ¯è®ºæ–‡
            
            è¿™ä¸ªå·¥å…·ç”¨äºæŸ¥è¯¢ä¸ç‰¹å®šå¤©ä½“ç›¸å…³çš„ç ”ç©¶æ–‡çŒ®ï¼ŒåŒ…æ‹¬ï¼š
            - è®ºæ–‡çš„BibCodeæ ‡è¯†ç¬¦
            - æœŸåˆŠåç§°
            - è®ºæ–‡æ ‡é¢˜
            - å‘è¡¨å¹´ä»½
            - å·å·å’Œé¡µç 
            - DOIé“¾æ¥
            
            å‚æ•°:
                object_id (str): å¤©ä½“æ ‡è¯†ç¬¦ï¼Œå¦‚ 'M13', 'NGC 6205', 'Vega' ç­‰
            
            è¿”å›:
                str: åŒ…å«å‚è€ƒæ–‡çŒ®åˆ—è¡¨çš„JSONæ ¼å¼å­—ç¬¦ä¸²
            
            ä½¿ç”¨åœºæ™¯:
            - ç”¨æˆ·è¯¢é—®å¤©ä½“çš„ç ”ç©¶æ–‡çŒ®
            - éœ€è¦æŸ¥æ‰¾ç›¸å…³çš„å­¦æœ¯è®ºæ–‡
            - äº†è§£å¤©ä½“çš„ç ”ç©¶å†å²
            """
            try:
                result = _get_bibliographic_data(object_id)
                return str(result)
            except Exception as e:
                return f"æ–‡çŒ®æŸ¥è¯¢å¤±è´¥: {str(e)}"
        
        @tool
        def search_objects_by_coordinates(ra: float, dec: float, radius: float = 0.1) -> str:
            """
            æ ¹æ®å¤©çƒåæ ‡æœç´¢é™„è¿‘çš„å¤©ä½“å¯¹è±¡
            
            è¿™ä¸ªå·¥å…·ç”¨äºåœ¨æŒ‡å®šåæ ‡å‘¨å›´æœç´¢å¤©ä½“ï¼ŒåŒ…æ‹¬ï¼š
            - æœç´¢ä¸­å¿ƒåæ ‡ï¼ˆèµ¤ç»ã€èµ¤çº¬ï¼‰
            - æœç´¢åŠå¾„
            - æ‰¾åˆ°çš„å¤©ä½“åˆ—è¡¨
            - æ¯ä¸ªå¤©ä½“çš„è·ç¦»å’Œç±»å‹
            
            å‚æ•°:
                ra (float): èµ¤ç»åæ ‡ï¼ˆåº¦ï¼‰ï¼ŒèŒƒå›´0-360
                dec (float): èµ¤çº¬åæ ‡ï¼ˆåº¦ï¼‰ï¼ŒèŒƒå›´-90åˆ°90
                radius (float): æœç´¢åŠå¾„ï¼ˆåº¦ï¼‰ï¼Œé»˜è®¤0.1åº¦
            
            è¿”å›:
                str: åŒ…å«æœç´¢ç»“æœçš„JSONæ ¼å¼å­—ç¬¦ä¸²
            
            ä½¿ç”¨åœºæ™¯:
            - ç”¨æˆ·æä¾›åæ ‡éœ€è¦æœç´¢é™„è¿‘å¤©ä½“
            - éœ€è¦äº†è§£æŸä¸ªåŒºåŸŸçš„å¤©ä½“åˆ†å¸ƒ
            - å¯»æ‰¾ç‰¹å®šåæ ‡é™„è¿‘çš„å¤©ä½“å¯¹è±¡
            """
            try:
                result = _search_objects_by_coordinates(ra, dec, radius)
                return str(result)
            except Exception as e:
                return f"åæ ‡æœç´¢å¤±è´¥: {str(e)}"
        
        self.mcp_tools = [get_object_by_identifier, get_bibliographic_data, search_objects_by_coordinates]
        logger.info("çœŸå®å·¥å…·è®¾ç½®å®Œæˆï¼ˆç›´æ¥è°ƒç”¨å·¥å…·å‡½æ•°ï¼‰")
    
    def _build_graph(self):
        """æ„å»ºLangGraphæŸ¥è¯¢æµç¨‹"""
        # åˆ›å»ºå·¥å…·èŠ‚ç‚¹
        tool_node = ToolNode(self.mcp_tools)
        
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(State)
        
        # æ·»åŠ èŠ‚ç‚¹ - ç®€åŒ–æµç¨‹ï¼Œè®©LLMç›´æ¥é€‰æ‹©å·¥å…·
        workflow.add_node("agent", self._agent_node)
        workflow.add_node("tools", tool_node)
        
        # è®¾ç½®è¾¹ - ç®€åŒ–çš„å·¥ä½œæµ
        workflow.set_entry_point("agent")
        workflow.add_conditional_edges(
            "agent",
            self._should_continue,
            {
                "continue": "tools",
                "end": END
            }
        )
        workflow.add_edge("tools", "agent")
        
        # ç¼–è¯‘å›¾
        self.graph = workflow.compile()
        logger.info("LangGraph æŸ¥è¯¢æµç¨‹æ„å»ºå®Œæˆ")
    
    async def _agent_node(self, state: State) -> State:
        """æ™ºèƒ½ä»£ç†èŠ‚ç‚¹ - è®©LLMè‡ªå·±é€‰æ‹©å·¥å…·"""
        messages = state["messages"]
        
        # æ„å»ºç³»ç»Ÿæç¤ºï¼Œè®©LLMäº†è§£å¯ç”¨çš„å·¥å…·
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤©ä½“ç‰©ç†å­¦åŠ©æ‰‹ï¼Œå¯ä»¥è®¿é—®ä»¥ä¸‹å·¥å…·æ¥æŸ¥è¯¢å¤©ä½“æ•°æ®ï¼š

1. get_object_by_identifier(object_id: str) - è·å–å¤©ä½“çš„åŸºç¡€ä¿¡æ¯
   - ç”¨äºæŸ¥è¯¢å¤©ä½“çš„åæ ‡ã€è§†å·®ã€å¾„å‘é€Ÿåº¦ç­‰åŸºæœ¬å‚æ•°
   - é€‚ç”¨äºï¼šè¯¢é—®å¤©ä½“åŸºæœ¬ä¿¡æ¯ã€åæ ‡ã€ç‰©ç†å‚æ•°ç­‰

2. get_bibliographic_data(object_id: str) - è·å–å¤©ä½“çš„å‚è€ƒæ–‡çŒ®
   - ç”¨äºæŸ¥è¯¢ä¸å¤©ä½“ç›¸å…³çš„ç ”ç©¶è®ºæ–‡å’Œå­¦æœ¯æ–‡çŒ®
   - é€‚ç”¨äºï¼šè¯¢é—®ç ”ç©¶æ–‡çŒ®ã€å­¦æœ¯è®ºæ–‡ã€ç ”ç©¶å†å²ç­‰

3. search_objects_by_coordinates(ra: float, dec: float, radius: float) - åæ ‡æœç´¢
   - ç”¨äºåœ¨æŒ‡å®šåæ ‡å‘¨å›´æœç´¢å¤©ä½“
   - é€‚ç”¨äºï¼šæä¾›åæ ‡æœç´¢å¤©ä½“ã€äº†è§£åŒºåŸŸå¤©ä½“åˆ†å¸ƒç­‰

è¯·æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·å¹¶è°ƒç”¨ã€‚å¦‚æœéœ€è¦å¤šä¸ªå·¥å…·ï¼Œå¯ä»¥ä¾æ¬¡è°ƒç”¨ã€‚
"""
        
        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        if not messages or not isinstance(messages[0], SystemMessage):
            messages = [SystemMessage(content=system_prompt)] + messages
        
        try:
            # ç»‘å®šå·¥å…·åˆ°LLMå¹¶è°ƒç”¨
            llm_with_tools = self.llm.bind_tools(self.mcp_tools)
            response = await llm_with_tools.ainvoke(messages)
            messages.append(response)
            
            # åªæ‰“å°å·¥å…·é€‰æ‹©ä¿¡æ¯
            if hasattr(response, 'tool_calls') and response.tool_calls:
                logger.info(f"ğŸ”§ é€‰æ‹©å·¥å…·: {[tool_call['name'] for tool_call in response.tool_calls]}")
            else:
                logger.info("ğŸ“ ç›´æ¥è¿”å›æ–‡æœ¬å“åº”")
            
            state["messages"] = messages
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½ä»£ç†èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
            error_message = AIMessage(content=f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºç°é”™è¯¯: {str(e)}")
            messages.append(error_message)
            state["messages"] = messages
        
        return state
    
    def _should_continue(self, state: State) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­æ‰§è¡Œå·¥å…·"""
        messages = state["messages"]
        last_message = messages[-1]
        
        # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯åŒ…å«å·¥å…·è°ƒç”¨ï¼Œåˆ™ç»§ç»­
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "continue"
        else:
            # è®¾ç½®æœ€ç»ˆå“åº”
            if hasattr(last_message, 'content') and last_message.content:
                state["final_response"] = last_message.content
            else:
                state["final_response"] = "æŸ¥è¯¢å®Œæˆï¼Œä½†æ²¡æœ‰è¿”å›ç»“æœ"
            return "end"
    
    async def _analyze_query(self, state: State) -> State:
        """åˆ†æç”¨æˆ·æŸ¥è¯¢"""
        user_query = state["user_query"]
        
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªå¤©ä½“ç‰©ç†å­¦æŸ¥è¯¢åŠ©æ‰‹ã€‚åˆ†æç”¨æˆ·çš„æŸ¥è¯¢æ„å›¾ï¼Œç¡®å®šéœ€è¦ä»€ä¹ˆç±»å‹çš„å¤©æ–‡æ•°æ®ã€‚

å¯ç”¨çš„æŸ¥è¯¢ç±»å‹ï¼š
1. åŸºç¡€ä¿¡æ¯æŸ¥è¯¢ - è·å–å¤©ä½“çš„åæ ‡ã€è§†å·®ã€å¾„å‘é€Ÿåº¦ç­‰åŸºæœ¬å‚æ•°
2. æ–‡çŒ®æŸ¥è¯¢ - è·å–ä¸å¤©ä½“ç›¸å…³çš„ç ”ç©¶è®ºæ–‡å’Œå‚è€ƒæ–‡çŒ®
3. åæ ‡æœç´¢ - æ ¹æ®å¤©çƒåæ ‡æœç´¢é™„è¿‘çš„å¤©ä½“

è¯·ç®€è¦åˆ†æç”¨æˆ·æŸ¥è¯¢çš„æ„å›¾ã€‚
"""
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"ç”¨æˆ·æŸ¥è¯¢: {user_query}")
        ]
        
        try:
            response = await self.llm.ainvoke(messages)
            analysis = response.content
            
            state["messages"].append(AIMessage(content=f"æŸ¥è¯¢åˆ†æ: {analysis}"))
            logger.info(f"æŸ¥è¯¢åˆ†æå®Œæˆ: {analysis[:100]}...")
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢åˆ†æå¤±è´¥: {str(e)}")
            state["messages"].append(AIMessage(content=f"æŸ¥è¯¢åˆ†æå¤±è´¥: {str(e)}"))
        
        return state
    
    async def _select_tools(self, state: State) -> State:
        """é€‰æ‹©åˆé€‚çš„å·¥å…·"""
        user_query = state["user_query"]
        
        # å·¥å…·é€‰æ‹©é€»è¾‘
        selected_tools = []
        query_lower = user_query.lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤©ä½“åç§°æˆ–æ ‡è¯†ç¬¦
        if any(keyword in query_lower for keyword in ['m13', 'ngc', 'vega', 'sirius', 'basic info', 'information']):
            selected_tools.append("get_object_by_identifier")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–‡çŒ®ä¿¡æ¯
        if any(keyword in query_lower for keyword in ['reference', 'paper', 'bibliography', 'literature', 'publication']):
            selected_tools.append("get_bibliographic_data")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åæ ‡æœç´¢
        if any(keyword in query_lower for keyword in ['coordinate', 'ra', 'dec', 'search', 'nearby']):
            selected_tools.append("search_objects_by_coordinates")
        
        # å¦‚æœæ²¡æœ‰æ˜ç¡®åŒ¹é…ï¼Œé»˜è®¤ä½¿ç”¨åŸºç¡€ä¿¡æ¯æŸ¥è¯¢
        if not selected_tools:
            selected_tools.append("get_object_by_identifier")
        
        state["selected_tools"] = selected_tools
        logger.info(f"é€‰æ‹©çš„å·¥å…·: {selected_tools}")
        
        return state
    
    async def _generate_response(self, state: State) -> State:
        """ç”Ÿæˆæœ€ç»ˆå“åº”"""
        user_query = state["user_query"]
        tool_results = state.get("query_results", {})
        
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤©ä½“ç‰©ç†å­¦åŠ©æ‰‹ã€‚åŸºäºå·¥å…·æŸ¥è¯¢çš„ç»“æœï¼Œä¸ºç”¨æˆ·æä¾›æ¸…æ™°ã€å‡†ç¡®çš„å›ç­”ã€‚

è¯·ï¼š
1. æ€»ç»“æŸ¥è¯¢ç»“æœçš„å…³é”®ä¿¡æ¯
2. ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šå¤©æ–‡æ•°æ®
3. å¦‚æœæœ‰å¤šä¸ªç»“æœï¼Œè¿›è¡Œé€‚å½“çš„ç»„ç»‡å’Œåˆ†ç±»
4. ä¿æŒç§‘å­¦ä¸¥è°¨æ€§çš„åŒæ—¶ï¼Œç¡®ä¿å¯è¯»æ€§
"""
        
        # æ„å»ºåŒ…å«å·¥å…·ç»“æœçš„æ¶ˆæ¯
        context = f"ç”¨æˆ·æŸ¥è¯¢: {user_query}\n\nå·¥å…·æŸ¥è¯¢ç»“æœ:\n"
        for tool_name, result in tool_results.items():
            context += f"\n{tool_name}: {result}\n"
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=context)
        ]
        
        try:
            response = await self.llm.ainvoke(messages)
            final_response = response.content
            
            state["final_response"] = final_response
            state["messages"].append(AIMessage(content=final_response))
            logger.info("æœ€ç»ˆå“åº”ç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            logger.error(f"å“åº”ç”Ÿæˆå¤±è´¥: {str(e)}")
            error_response = f"æŠ±æ­‰ï¼Œå“åº”ç”Ÿæˆæ—¶å‡ºç°é”™è¯¯: {str(e)}"
            state["final_response"] = error_response
            state["messages"].append(AIMessage(content=error_response))
        
        return state
    
    async def query(self, user_input: str) -> str:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        logger.info(f"ğŸš€ æ‰§è¡ŒæŸ¥è¯¢: {user_input}")
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = {
            "messages": [HumanMessage(content=user_input)],
            "user_query": user_input,
            "selected_tools": [],
            "query_results": {},
            "final_response": ""
        }
        
        try:
            # æ‰§è¡Œå›¾æµç¨‹ï¼Œè®¾ç½®é€’å½’é™åˆ¶
            config = {"recursion_limit": 10}
            result = await self.graph.ainvoke(initial_state, config=config)
            
            # å¦‚æœæ²¡æœ‰final_responseï¼Œä»æœ€åä¸€æ¡æ¶ˆæ¯ä¸­è·å–
            if not result.get("final_response"):
                messages = result.get("messages", [])
                if messages:
                    last_message = messages[-1]
                    if hasattr(last_message, 'content') and last_message.content:
                        result["final_response"] = last_message.content
            
            final_response = result.get("final_response", "æŸ¥è¯¢å®Œæˆï¼Œä½†æ²¡æœ‰è¿”å›ç»“æœ")
            logger.info("âœ… æŸ¥è¯¢å®Œæˆ")
            
            return final_response
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}")
            return f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    def query_sync(self, user_input: str) -> str:
        """åŒæ­¥æŸ¥è¯¢æ¥å£"""
        return asyncio.run(self.query(user_input))

async def main():
    """ä¸»å‡½æ•° - äº¤äº’å¼æŸ¥è¯¢ç•Œé¢"""
    print("=" * 60)
    print("ğŸŒŸ å¤©ä½“ç‰©ç†å­¦TAPæŸ¥è¯¢ç³»ç»Ÿ - LangGraphå®¢æˆ·ç«¯")
    print("=" * 60)
    print("æ”¯æŒçš„æŸ¥è¯¢ç±»å‹:")
    print("1. å¤©ä½“åŸºç¡€ä¿¡æ¯: 'Give me basic info about M13'")
    print("2. å‚è€ƒæ–‡çŒ®: 'Find references for Vega'")
    print("3. åæ ‡æœç´¢: 'Search objects near RA=250.4, DEC=36.5'")
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("=" * 60)
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    try:
        client = AstrophysicsQueryClient()
        print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return
    
    # äº¤äº’å¾ªç¯
    while True:
        try:
            user_input = input("\nğŸ” è¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            if not user_input:
                continue
            
            print("\nâ³ æ­£åœ¨å¤„ç†æŸ¥è¯¢...")
            response = await client.query(user_input)
            
            print("\nğŸ“‹ æŸ¥è¯¢ç»“æœ:")
            print("-" * 40)
            print(response)
            print("-" * 40)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ æŸ¥è¯¢å‡ºé”™: {str(e)}")

def create_client():
    """åˆ›å»ºå®¢æˆ·ç«¯å®ä¾‹ - ç”¨äºéäº¤äº’å¼è°ƒç”¨"""
    try:
        return AstrophysicsQueryClient()
    except Exception as e:
        logger.error(f"å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {str(e)}")
        raise

def query_astro_data(user_input: str) -> str:
    """
    åŒæ­¥æŸ¥è¯¢æ¥å£ - ç”¨äºé›†æˆåˆ°å…¶ä»–æ¨¡å—
    
    Args:
        user_input: ç”¨æˆ·æŸ¥è¯¢è¾“å…¥
        
    Returns:
        str: æŸ¥è¯¢ç»“æœ
    """
    try:
        client = create_client()
        return client.query_sync(user_input)
    except Exception as e:
        logger.error(f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}")
        return f"æ•°æ®æ£€ç´¢å¤±è´¥: {str(e)}"

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œé”™è¯¯: {str(e)}")